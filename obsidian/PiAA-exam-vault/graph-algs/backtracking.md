# info
1) [algorithm](#algorithm)
	- [backtracking](##backtracking)
		- [queen-problem](###queen-problem)
		- [branch-and-boundary](###branch-and-boundary)
		- [additional-optimizations](###additional-optimizations)
			- [tail-recursion](####tail-recursion)
	- [monte-carlo](##monte-carlo)
		- [area-calculating](###area-calculating)
		- [tree-size-estimating](###tree-size-estimating)
2) [usage](#usage)
3) [complexity](#complexity)
4) [content](#content)

# algorithm

## backtracking
Алгоритм поиска с возвратом.

Метод решения задачи перебора всех возможных вариантов с последующим выбором оптимального решения.

Основной идеей является перебор всех возможных решений путем последовательного выбора вариантов и проверки их на соответствие заданным условиям.

**Шаги алгоритма:**
1) **Инициализация:** выбор подходящего элемента или состояния, чтобы продолжить решение задачи.
2) **Проверка:** текущий выбранный элемент или состояние проверяется на соответствие критериям или ограничениям задачи. Если проверка проходит успешно, то мы переходим к следующему шагу. Иначе: возвращает элемент, чтобы выбрать другой и повторить проверку.
3) **Откат:** возврат к предыдущему выбору и проверке, когда все возможные варианты были исчерпаны в данной ветви графа состояний или когда текущий выбор не приводит к решению задачи.
4) **Продолжение:** продолжаем алгоритм, используя текущий выбор и двигаясь вперед к нахождению следующего возможного варианта или решения задачи. Этот шаг может повторяться до тех пор, пока все возможные комбинации не будут найдены или пока задача не будет решена.

### queen-problem
Задача о ферзях.

**Формулировка:**
Необходимо разместить N ферзей на доске N×N так, чтобы ни один из них не бил другого. 

Классическое решение использует backtracking (поиск с возвратом).

**Шаги алгоритма:**
1) Задаем пустую доску.
2) Ставим ферзя в любую пустую клетку.
	1) Если после добавления нового ферзя находятся пересечения, то: откат + повтор п. (2)
	2) Если расставлено N ферзей: победа
	3) Если count(ферзей) < N: повтор п. (2) только без отката.

```Python
while (не все решения найдены)
	while (множество состояний не пусто)
		двигаться вперед
		if (решение)
			добавить в решения
			...
		else
			откат
			...
```

**Сложность алгоритма:**
- **Полный перебор:**
	- **По времени:** `O(C_(N^2)_N)` (выбираем N клеток для ферзей из N^2 имеющихся)
	- **По памяти:** `O(N^2)` (хранение доски)

### branch-and-boundary
Метод ветвей и границ. 

Метод является развитием метода полного перебора, в отличие от последнего - с отсевом подмножеств допустимых решений, заведомо не содержащих оптимальных решений.

**Шаги алгоритма:**
	1) **Разбиение:** общее множество допустимых решений разбивается на меньшие подмножества, которые затем исследуются.
	2) **Определение границ:** для каждого подмножества определяется граница (оценка) наилучшего возможного решения внутри этого подмножества.
	3) **Отсечение:** если граница некоторого подмножества хуже, чем уже найденное решение, то это подмножество можно отсечь, не рассматривая его дальше. 
	4) **Продолжение:** процесс разбиения, оценки границ и отсечения ветвей продолжается до тех пор, пока не будет найдено оптимальное решение или не будет доказано, что оно не существует. 

**Границы для задачи о ферзях:**
- Не ставить ферзей на один и тот же столбец: `O(N^N)` (N ферзей, N строк для вставки)
- Не ставить ферзей на один и тот же столбец и в одну и ту же строку: `O(N!)` (для первого ферзя - N мест для вставки, для второго - N-1 ... для последнего - 1 место)
- Не ставить ферзей на один и тот же столбец, ту же строку, те же диагонали: `O(...)`(гораздо меньше сложность)

### additional-optimizations
Дополнительные оптимизации к задачам о ферзях.

**Оптимизации:**
- **Вращения/отражения:** разбить доску на 4 сектора --> 1 решение == 4 решения (через повороты доски).
- **Хвостовая  рекурсия:** использовать хвостовую рекурсию для оптимизации работы алгоритма на уровне компилятора.

#### tail-recursion
Хвостовая рекурсия.

Особый вид рекурсии, при которой рекурсивный вызов является последней операцией в функции. 

**Ключевая особенность:** после возврата из рекурсивного вызова не выполняется никаких дополнительных вычислений с результатом.

**Преимущество:** многие компиляторы могут оптимизировать её в итеративный цикл (tail call optimization), что исключает накладные расходы на создание дополнительных кадров стека и риск переполнения 
стека.

```Python
# НЕ хвостовая рекурсия (после вызова выполняется умножение)
def factorial(n):
    if n <= 1:
        return 1
    return n * factorial(n - 1)  # Требуется дополнительная операция после возврата

# Хвостовая рекурсия
def factorial_tail(n, acc=1):
    if n <= 1:
        return acc
    return factorial_tail(n - 1, n * acc)  # Последняя операция - рекурсивный вызов
```

Необходимость расширения стека при рекурсивных вызовах диктуется требованием восстановления состояния вызывающего экземпляра функции (то есть её параметров, локальных данных и адреса возврата) после возврата из рекурсивного вызова. 

Если рекурсивный вызов является последней операцией перед выходом из вызывающей функции и результатом вызывающей функции должен стать результат, который вернёт рекурсивный вызов, сохранение контекста уже не имеет значения — ни параметры, ни локальные переменные уже использоваться не будут, а адрес возврата уже находится в стеке. 

Поэтому в такой ситуации вместо полноценного рекурсивного вызова функции можно просто заменить значения параметров в стеке и передать управление на точку входа. 

До тех пор, пока исполнение будет идти по этой рекурсивной ветви, будет, фактически, выполняться обычный цикл. Когда рекурсия завершится (то есть исполнение пройдёт по терминальной ветви и достигнет команды возврата из функции) возврат произойдёт сразу в исходную точку, откуда произошёл вызов рекурсивной функции. Таким образом, при любой глубине рекурсии стек переполнен не будет.

**Обычная рекурсия:**
![[Pasted image 20250601141413.png]]

**Хвостовая рекурсия:**
![[Pasted image 20250601141437.png]]

## monte-carlo
Класс вероятностных алгоритмов.

Методы Монте-Карло представляют собой широкий класс вычислительных алгоритмов, которые полагаются на повторяющуюся случайную выборку для получения численных результатов.

**Основная концепция:** использование случайности для решения проблем, которые в принципе могут быть детерминированными.

**Ограниченности метода:**
- **Медленная сходимость:** `O(1/sqrt(N))`(для повышения точности в 10 раз требуется увеличить число испытаний в 100 раз)
- **Случайные числа:** зависимость от качества генератора случайных чисел.

### area-calculating
Вычисление площади сложных аналитических фигур.

**Шаги алгоритма:**
1) Помещаем фигуру сложной формы в простую фигуру известной площади (прямоугольник).
2) Генерируем N случайных точек, равномерно распределенных внутри простой фигуры.
3) Считаем M - количество точек, попавших внутрь искомой фигуры.
4) Оцениваем площадь: `S = (M/N) * площадь_прямоугольника`.

**Точность:** ошибка пропорциональна `1/sqrt(N)` - для увеличения точности в 10 раз нужно 100 раз больше точек.
### tree-size-estimating
Вычисление размера дерева.

**Шаги алгоритма:**
1) Идем по уровням дерева вниз, начиная от корня.
2) Для каждого уровня число разветвлений равно `N0 * N1 * ... * Nk`, где:
	- `N0` - число разветвлений на нулевом уровне (уровне корня).
	- `Ni` - число разветвлений на предыдущих уровнях.
	- `Nk` - число разветвлений на текущем уровне.
3) Итоговый размер дерева, полученный через этот маршрут, составляется из суммы разветвлений по уровням.
4) Для повышения точности можно запустить несколько маршрутов. Итоговый размер дерева - среднее от суммы результатов по маршрутам.

![[Pasted image 20250601144959.png]]

# usage
**backtracking:**
- Решение NP трудных задач (с использованием метода ветвей и границ).

**monte-carlo:**
- Вычисление площадей.
- Нефтедобыча.

# complexity
**backtracking:**
- **quenn-problem:**
	- **По времени:** `O(N!)` (лучшее, что давалось) (зависит от способа отсечения)
	- **По памяти:** `O(N^2)` (необходимость хранения доски)

**monte-carlo:**
ОЦЕНКУ СЛОЖНОСТИ НА ПАРАХ НЕ ДАВАЛИ!!!
- **area-calculating:**
	- **По времени:** `O(N)` (число точек)
	- **По памяти:** `O(1)` (сами точки хранить не обязательно)

- **tree-size-estimating:**
	- **По времени:** `O(h*n)` (где `h` - средняя глубина, `n` - число выборок)
	- **По памяти:** `O(N)` (число вершин в дереве)
# content
- [backtracking](https://habr.com/ru/companies/otus/articles/746408/)
- [tail-recursion](https://ru.wikipedia.org/wiki/%D0%A5%D0%B2%D0%BE%D1%81%D1%82%D0%BE%D0%B2%D0%B0%D1%8F_%D1%80%D0%B5%D0%BA%D1%83%D1%80%D1%81%D0%B8%D1%8F)
- [monte-carlo](https://habr.com/ru/articles/835870/)